analysis:
  max_entities: 
    10001
  max_time:
    100000.0 # 1/10 year
  max_real_time:
    60 * 60 * 1000 # ms
  initial_entities:
    10000
  use_barabasi: false # if this is set to 1, the global follow rate will be ignored. Follow thresholds not needed.
  use_random_time_increment: true # increments by 1/sum(rates) on average
  use_flawed_followback: false
  follow_model: random # Accepted models: 'random', 'preferential', 'entity', 'preferential-entity'
  unfollow_tweet_rate: 0 # 10 tweets/day

rates:
  # Rate for creating entities
  add: {function: constant, value: 0.0}

output:
  save_network_on_timeout: # Should we save all our data if we hit >= max_real_time?
     true
  save_file: # File to save to, and load from
    network_state.sav
  stdout_basic: true
  stdout_summary: true
  visualize: true
  verbose: true
  entity_stats: true
  degree_distributions: true
  tweet_analysis: true

tweet_ranks: 
  thresholds: {bin_spacing: linear, min: 10, max: 300, increment: 10}
retweet_ranks:
  thresholds: {bin_spacing: linear, min: 10, max: 300, increment: 10}
follow_ranks:
  thresholds: {bin_spacing: linear, min: 0, max: 100001, increment: 1}
  weights:    {bin_spacing: linear, min: 1, max: 100000, increment: 1}

languages:
  weights:
    English: 100
    French: 25
    French+English: 25

tweet_observation: # 'Omega'
   # Configures an observation probability density function that gives 
   # the probability that a tweet is observed at a certain time by an 'ideal observer'. 
   # An 'ideal observer' is one which always sees a tweet, eventually.'
   # The observation PDF is used for both retweeting and follow-from-tweet.
   # We combine this with a relevance factor, r, where 0 <= r <= 1.0, we in turn
   # determines the probability that a given entity will act on a given tweet.

   half_life: 22.5 # In minutes. Determines half-life of exponetial decay.
   initial_resolution: 0.01 # In minutes. The time-step with which to begin binning.
   final_rate: 0.001 # A final value when to stop binning our omega function.

tweet_relevance:
    # Determine amount of discrete bins
    # These values should match your C++ config_static.h limits!!
    # Distance is the value [0...1] determined by a modular distance function.
    humour_bins: 2
    distance_bins: 4

    # Determine traits relevant to the relevance determination function 
    # Relevance functions are automatically converted into the necessary tables
    # using Python. The strings provided can be any valid Python, as if wrapped by a
    # Python function as such:
    #
    # def FOO(entity_type, humour, distance): 
    #   return $FOO

    preference_classes:
      - name: LoveEverything
        retweet_relevance:
          all: 0.0001 # Can be any valid Python code
      - name: HateEverything
        retweet_relevance:
          all: 0 # Can be any valid Python code

entities:
  - name: Standard
    weights:
      # Weight with which this entity is created
      add: 80 
      # Weight with which this entity is followed in preferential follow
      follow: 5
    # Probability that following this entity results in a follow-back
    followback_probability: 40
    rates: 
        # Rate for follows from this entity:
        follow: {function: constant, value: 0.1}
        # Rate for tweets from this entity:
        tweet: {function: constant, value: 0.001}

  - name: Celebrity
    weights: {add: 5, follow: 80}
    followback_probability: 0
    rates:
        follow: {function: constant, value: 0.1}
        tweet: {function: constant, value: 0.001}

  - name: Bot
    weights: {add: 5, follow: 0}
    followback_probability: 0
    rates:
        follow: {function: constant, value: 0.1}
        tweet: {function: constant, value: 0.001}

  - name: Organization
    weights: {add: 10, follow: 15}
    followback_probability: 0
    rates:
        follow: {function: constant, value: 0.1}
        tweet: {function: constant, value: 0.001}
